**Normalization Strategy:**  
normalization with a different scaler for every company

**Learning Rate:** 0.001

**Batch Size:** 50

**Activation functions:** used tanh, sigmoid and ReLu
